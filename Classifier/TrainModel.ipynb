{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "from helpers.AudioVisionDataset import AudioVisionDataset\n",
    "from helpers.ModelLayout import AudioVisionModel\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = \"../DataAnalysis/8KFeatures.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featuresdf = pd.read_csv(features_file)\n",
    "# temp = literal_eval(featuresdf['feature'][0])\n",
    "# print(temp)\n",
    "# print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "av_dataset = AudioVisionDataset(features_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.667 * len(av_dataset))\n",
    "test_size = len(av_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(av_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AudioVisionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "train_data_loader = data.DataLoader(train_dataset, shuffle = True)\n",
    "test_data_loader = data.DataLoader(test_dataset, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 14, 13, 108]              70\n",
      "         MaxPool2d-2            [-1, 14, 6, 54]               0\n",
      "            Conv2d-3            [-1, 28, 5, 53]           1,596\n",
      "         MaxPool2d-4            [-1, 28, 2, 26]               0\n",
      "            Linear-5                   [-1, 64]          93,248\n",
      "           Dropout-6                   [-1, 64]               0\n",
      "            Linear-7                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 95,564\n",
      "Trainable params: 95,564\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.25\n",
      "Params size (MB): 0.36\n",
      "Estimated Total Size (MB): 0.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (1,14, 109))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def trainNet(net, n_epochs):\n",
    "    \n",
    "    #Print all of the hyperparameters of the training iteration:\n",
    "    print(\"===== HYPERPARAMETERS =====\")\n",
    "    print(\"batch_size=\", 174)\n",
    "    print(\"epochs=\", n_epochs)\n",
    "    print(\"learning_rate=\", 0.001)\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    n_batches = len(train_data_loader)\n",
    "    \n",
    "    #Time for printing\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    #Loop for n_epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        print_every = n_batches // 10\n",
    "        start_time = time.time()\n",
    "        total_train_loss = 0\n",
    "        count = 0\n",
    "        \n",
    "        for i, data in enumerate(train_data_loader, 0):\n",
    "            count+= 1\n",
    "            \n",
    "            #Get inputs\n",
    "            inputs, labels = data\n",
    "            \n",
    "            #Wrap them in a Variable object\n",
    "            inputs, labels = Variable(inputs.unsqueeze(0)), Variable(labels)\n",
    "\n",
    "            #Set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward pass, backward pass, optimize\n",
    "            outputs = net(inputs)\n",
    "            loss_size = loss(outputs, labels)\n",
    "            loss_size.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Print statistics\n",
    "            running_loss += loss_size.data\n",
    "            total_train_loss += loss_size.data\n",
    "            \n",
    "            #Print every 10th batch of an epoch\n",
    "            if (i + 1) % (print_every + 1) == 0:\n",
    "                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
    "                        epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
    "                #Reset running loss and time\n",
    "                running_loss = 0.0\n",
    "                start_time = time.time()\n",
    "            \n",
    "        #At the end of the epoch, do a pass on the validation set\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in test_data_loader:\n",
    "            \n",
    "            count += 1\n",
    "            #Wrap tensors in Variables\n",
    "            inputs, labels = Variable(inputs.unsqueeze(0)), Variable(labels)\n",
    "            \n",
    "            #Forward pass\n",
    "            val_outputs = net(inputs)\n",
    "            val_loss_size = loss(val_outputs, labels)\n",
    "            total_val_loss += val_loss_size.data\n",
    "            \n",
    "        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(test_data_loader)))\n",
    "        print(count)\n",
    "        \n",
    "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 174\n",
      "epochs= 2\n",
      "learning_rate= 0.001\n",
      "==============================\n",
      "Epoch 1, 10% \t train_loss: 2.28 took: 4.51s\n",
      "Epoch 1, 20% \t train_loss: 2.26 took: 4.47s\n",
      "Epoch 1, 30% \t train_loss: 2.26 took: 4.64s\n",
      "Epoch 1, 40% \t train_loss: 2.25 took: 5.73s\n",
      "Epoch 1, 50% \t train_loss: 2.26 took: 6.98s\n",
      "Epoch 1, 60% \t train_loss: 2.27 took: 4.69s\n",
      "Epoch 1, 70% \t train_loss: 2.25 took: 4.95s\n",
      "Epoch 1, 80% \t train_loss: 2.27 took: 4.54s\n",
      "Epoch 1, 90% \t train_loss: 2.26 took: 4.64s\n",
      "Validation loss = 2.26\n",
      "8732\n",
      "Epoch 2, 10% \t train_loss: 2.26 took: 4.69s\n",
      "Epoch 2, 20% \t train_loss: 2.25 took: 4.89s\n",
      "Epoch 2, 30% \t train_loss: 2.27 took: 4.67s\n",
      "Epoch 2, 40% \t train_loss: 2.26 took: 4.74s\n",
      "Epoch 2, 50% \t train_loss: 2.25 took: 4.46s\n",
      "Epoch 2, 60% \t train_loss: 2.28 took: 4.51s\n",
      "Epoch 2, 70% \t train_loss: 2.27 took: 4.38s\n",
      "Epoch 2, 80% \t train_loss: 2.25 took: 4.40s\n",
      "Epoch 2, 90% \t train_loss: 2.26 took: 4.41s\n",
      "Validation loss = 2.26\n",
      "8732\n",
      "Training finished, took 127.05s\n"
     ]
    }
   ],
   "source": [
    "trainNet(model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:audio-vision] *",
   "language": "python",
   "name": "conda-env-audio-vision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
